{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Poly\\\\Projects\\\\WebSpider\\\\Frontend\\\\src\\\\components\\\\Pages\\\\Crawler\\\\Crawler.js\",\n    _s = $RefreshSig$();\n\nimport { useState } from \"react\";\nimport { isValidUrl } from \"../../../util/validator\";\nimport ContentTable from \"../../Common/ContentTable\";\nimport SideMenu from \"../../Common/SideMenu\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst Crawler = () => {\n  _s();\n\n  const [pages, setPages] = useState([]);\n  const [state, setState] = useState({\n    ui: {\n      submit: false\n    },\n    pages: []\n  });\n\n  const resultCallback = res => {\n    // check result status\n    console.log(res);\n\n    if (res.status === \"success\") {\n      // case post success\n      setPages(old_pages => [...old_pages, ...res.pages]);\n    } else if (res.status === \"clear\") {\n      // case clear results\n      setPages([]);\n    }\n  };\n\n  const pageCallback = page => {\n    setPages([...pages, page]);\n  };\n\n  const getUrlValidation = event => {\n    setState({ ...state,\n      ui: { ...state.ui,\n        submit: isLink(event.target.value)\n      }\n    });\n  };\n\n  const handleSubmit = async e => {\n    e.preventDefault();\n    const {\n      url,\n      maxDepth,\n      maxPages\n    } = e.target.elements;\n    const options = {\n      url: url.value,\n      maxDepth: maxDepth.value,\n      maxPages: maxPages.value,\n      pages: []\n    };\n    await startCrawl({\n      options\n    });\n    console.log(state.pages.length);\n  };\n\n  const startCrawl = async ({\n    options\n  }) => {\n    const response = await crawlPage({\n      options\n    });\n\n    if (response.status !== 200) {\n      console.log(`[!] Crawl ended with status: ${response.status}`);\n      return;\n    }\n\n    const result = await response.json();\n    setState({ ...state,\n      pages: [...state.pages, result.url]\n    });\n    console.log(result);\n\n    if (!result.fin) {\n      await startCrawl({\n        options: result.options\n      });\n    }\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"crawlerPage\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      id: \"form-section\",\n      className: \"column sm\",\n      children: /*#__PURE__*/_jsxDEV(SideMenu, {\n        resultCallback: resultCallback,\n        pageCallback: pageCallback,\n        isLink: isValidUrl,\n        handleSubmit: handleSubmit,\n        getUrlValidation: getUrlValidation\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      id: \"view-section\",\n      className: \"column bg\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"row title\",\n        children: /*#__PURE__*/_jsxDEV(\"h2\", {\n          children: \"RESULTS\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 74,\n          columnNumber: 11\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 73,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(ContentTable, {\n        pages: pages,\n        isLink: isValidUrl\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 76,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 72,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 62,\n    columnNumber: 5\n  }, this);\n};\n\n_s(Crawler, \"Y+XilCW1jHYlNRpms6oq4HKl6bc=\");\n\n_c = Crawler;\nexport default Crawler;\n\nvar _c;\n\n$RefreshReg$(_c, \"Crawler\");","map":{"version":3,"sources":["C:/Users/Poly/Projects/WebSpider/Frontend/src/components/Pages/Crawler/Crawler.js"],"names":["useState","isValidUrl","ContentTable","SideMenu","Crawler","pages","setPages","state","setState","ui","submit","resultCallback","res","console","log","status","old_pages","pageCallback","page","getUrlValidation","event","isLink","target","value","handleSubmit","e","preventDefault","url","maxDepth","maxPages","elements","options","startCrawl","length","response","crawlPage","result","json","fin"],"mappings":";;;AAAA,SAASA,QAAT,QAAyB,OAAzB;AACA,SAASC,UAAT,QAA2B,yBAA3B;AACA,OAAOC,YAAP,MAAyB,2BAAzB;AACA,OAAOC,QAAP,MAAqB,uBAArB;;;AAEA,MAAMC,OAAO,GAAG,MAAM;AAAA;;AACpB,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBN,QAAQ,CAAC,EAAD,CAAlC;AACA,QAAM,CAACO,KAAD,EAAQC,QAAR,IAAoBR,QAAQ,CAAC;AACjCS,IAAAA,EAAE,EAAE;AACFC,MAAAA,MAAM,EAAE;AADN,KAD6B;AAIjCL,IAAAA,KAAK,EAAE;AAJ0B,GAAD,CAAlC;;AAOA,QAAMM,cAAc,GAAIC,GAAD,IAAS;AAC9B;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAYF,GAAZ;;AACA,QAAIA,GAAG,CAACG,MAAJ,KAAe,SAAnB,EAA8B;AAC5B;AACAT,MAAAA,QAAQ,CAAEU,SAAD,IAAe,CAAC,GAAGA,SAAJ,EAAe,GAAGJ,GAAG,CAACP,KAAtB,CAAhB,CAAR;AACD,KAHD,MAGO,IAAIO,GAAG,CAACG,MAAJ,KAAe,OAAnB,EAA4B;AACjC;AACAT,MAAAA,QAAQ,CAAC,EAAD,CAAR;AACD;AACF,GAVD;;AAWA,QAAMW,YAAY,GAAIC,IAAD,IAAU;AAC7BZ,IAAAA,QAAQ,CAAC,CAAC,GAAGD,KAAJ,EAAWa,IAAX,CAAD,CAAR;AACD,GAFD;;AAGA,QAAMC,gBAAgB,GAAIC,KAAD,IAAW;AAClCZ,IAAAA,QAAQ,CAAC,EACP,GAAGD,KADI;AAEPE,MAAAA,EAAE,EAAE,EAAE,GAAGF,KAAK,CAACE,EAAX;AAAeC,QAAAA,MAAM,EAAEW,MAAM,CAACD,KAAK,CAACE,MAAN,CAAaC,KAAd;AAA7B;AAFG,KAAD,CAAR;AAID,GALD;;AAMA,QAAMC,YAAY,GAAG,MAAOC,CAAP,IAAa;AAChCA,IAAAA,CAAC,CAACC,cAAF;AACA,UAAM;AAAEC,MAAAA,GAAF;AAAOC,MAAAA,QAAP;AAAiBC,MAAAA;AAAjB,QAA8BJ,CAAC,CAACH,MAAF,CAASQ,QAA7C;AACA,UAAMC,OAAO,GAAG;AACdJ,MAAAA,GAAG,EAAEA,GAAG,CAACJ,KADK;AAEdK,MAAAA,QAAQ,EAAEA,QAAQ,CAACL,KAFL;AAGdM,MAAAA,QAAQ,EAAEA,QAAQ,CAACN,KAHL;AAIdlB,MAAAA,KAAK,EAAE;AAJO,KAAhB;AAMA,UAAM2B,UAAU,CAAC;AAAED,MAAAA;AAAF,KAAD,CAAhB;AACAlB,IAAAA,OAAO,CAACC,GAAR,CAAYP,KAAK,CAACF,KAAN,CAAY4B,MAAxB;AACD,GAXD;;AAYA,QAAMD,UAAU,GAAG,OAAO;AAAED,IAAAA;AAAF,GAAP,KAAuB;AACxC,UAAMG,QAAQ,GAAG,MAAMC,SAAS,CAAC;AAAEJ,MAAAA;AAAF,KAAD,CAAhC;;AACA,QAAIG,QAAQ,CAACnB,MAAT,KAAoB,GAAxB,EAA6B;AAC3BF,MAAAA,OAAO,CAACC,GAAR,CAAa,gCAA+BoB,QAAQ,CAACnB,MAAO,EAA5D;AACA;AACD;;AACD,UAAMqB,MAAM,GAAG,MAAMF,QAAQ,CAACG,IAAT,EAArB;AACA7B,IAAAA,QAAQ,CAAC,EAAE,GAAGD,KAAL;AAAYF,MAAAA,KAAK,EAAE,CAAC,GAAGE,KAAK,CAACF,KAAV,EAAiB+B,MAAM,CAACT,GAAxB;AAAnB,KAAD,CAAR;AACAd,IAAAA,OAAO,CAACC,GAAR,CAAYsB,MAAZ;;AACA,QAAI,CAACA,MAAM,CAACE,GAAZ,EAAiB;AACf,YAAMN,UAAU,CAAC;AAAED,QAAAA,OAAO,EAAEK,MAAM,CAACL;AAAlB,OAAD,CAAhB;AACD;AACF,GAZD;;AAcA,sBACE;AAAK,IAAA,SAAS,EAAC,aAAf;AAAA,4BACE;AAAK,MAAA,EAAE,EAAC,cAAR;AAAuB,MAAA,SAAS,EAAC,WAAjC;AAAA,6BACE,QAAC,QAAD;AACE,QAAA,cAAc,EAAEpB,cADlB;AAEE,QAAA,YAAY,EAAEM,YAFhB;AAGE,QAAA,MAAM,EAAEhB,UAHV;AAIE,QAAA,YAAY,EAAEuB,YAJhB;AAKE,QAAA,gBAAgB,EAAEL;AALpB;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,YADF,eAUE;AAAK,MAAA,EAAE,EAAC,cAAR;AAAuB,MAAA,SAAS,EAAC,WAAjC;AAAA,8BACE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA,+BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,cADF,eAIE,QAAC,YAAD;AAAc,QAAA,KAAK,EAAEd,KAArB;AAA4B,QAAA,MAAM,EAAEJ;AAApC;AAAA;AAAA;AAAA;AAAA,cAJF;AAAA;AAAA;AAAA;AAAA;AAAA,YAVF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAmBD,CA1ED;;GAAMG,O;;KAAAA,O;AA2EN,eAAeA,OAAf","sourcesContent":["import { useState } from \"react\";\r\nimport { isValidUrl } from \"../../../util/validator\";\r\nimport ContentTable from \"../../Common/ContentTable\";\r\nimport SideMenu from \"../../Common/SideMenu\";\r\n\r\nconst Crawler = () => {\r\n  const [pages, setPages] = useState([]);\r\n  const [state, setState] = useState({\r\n    ui: {\r\n      submit: false,\r\n    },\r\n    pages: [],\r\n  });\r\n\r\n  const resultCallback = (res) => {\r\n    // check result status\r\n    console.log(res);\r\n    if (res.status === \"success\") {\r\n      // case post success\r\n      setPages((old_pages) => [...old_pages, ...res.pages]);\r\n    } else if (res.status === \"clear\") {\r\n      // case clear results\r\n      setPages([]);\r\n    }\r\n  };\r\n  const pageCallback = (page) => {\r\n    setPages([...pages, page]);\r\n  };\r\n  const getUrlValidation = (event) => {\r\n    setState({\r\n      ...state,\r\n      ui: { ...state.ui, submit: isLink(event.target.value) },\r\n    });\r\n  };\r\n  const handleSubmit = async (e) => {\r\n    e.preventDefault();\r\n    const { url, maxDepth, maxPages } = e.target.elements;\r\n    const options = {\r\n      url: url.value,\r\n      maxDepth: maxDepth.value,\r\n      maxPages: maxPages.value,\r\n      pages: [],\r\n    };\r\n    await startCrawl({ options });\r\n    console.log(state.pages.length);\r\n  };\r\n  const startCrawl = async ({ options }) => {\r\n    const response = await crawlPage({ options });\r\n    if (response.status !== 200) {\r\n      console.log(`[!] Crawl ended with status: ${response.status}`);\r\n      return;\r\n    }\r\n    const result = await response.json();\r\n    setState({ ...state, pages: [...state.pages, result.url] });\r\n    console.log(result);\r\n    if (!result.fin) {\r\n      await startCrawl({ options: result.options });\r\n    }\r\n  };\r\n\r\n  return (\r\n    <div className=\"crawlerPage\">\r\n      <div id=\"form-section\" className=\"column sm\">\r\n        <SideMenu\r\n          resultCallback={resultCallback}\r\n          pageCallback={pageCallback}\r\n          isLink={isValidUrl}\r\n          handleSubmit={handleSubmit}\r\n          getUrlValidation={getUrlValidation}\r\n        />\r\n      </div>\r\n      <div id=\"view-section\" className=\"column bg\">\r\n        <div className=\"row title\">\r\n          <h2>RESULTS</h2>\r\n        </div>\r\n        <ContentTable pages={pages} isLink={isValidUrl}></ContentTable>\r\n      </div>\r\n    </div>\r\n  );\r\n};\r\nexport default Crawler;\r\n"]},"metadata":{},"sourceType":"module"}